# data-tapestry
data is the new oil

Understanding the Data is Priority #1
Stop me if you’ve heard this one before: “Data is the New Oil.”

It means data is being used everywhere, just like oil was in the 20th century. As a data scientist, you’ll probably end up working on data from all sorts of industries and fields.

Without understanding what that data means, and how you have to approach it, all the data science methods will be useless.

Having a basic understanding of the data features and how they connect to the end goal will help you create a pipeline for data wrangling, analysis, and prediction.

So, ask as many questions as you need to understand when you’re handed a project. Don’t leave ambiguities hanging until the deadline. One answer to the right question could make or break your model.

2. Basic EDA Will Save You a Lot of Trouble
Exploratory Data Analysis (EDA) is a primary step in data analysis. Using EDA will help you build a roadmap to your goal.

It comprises of visualization techniques, data exploration, description, and data feature connection.

These techniques include:

- Missing Value Analysis (MVA)
This technique will help you figure out which parts of your data are missing. More than that, it will tell you if there is a pattern in their absence.

Basic Missing Number Analysis to Show Gaps in Data
Missing Number Analysis can identify which features may be closely related and thus used to fill gaps
Perhaps you’ll notice synchronous gaps in data, or perhaps you’ll notice data features you don’t need at all.

This basic insight into the data will help you decide on how to proceed.

Maybe you’ll decide to compensate for the absent data by using any number of techniques like Interpolation, or Imputation. Or maybe you’ll decide to trim your data through outlier analysis.

You may also choose to extract the missing data from other sources to complete your data set.

This will prepare your data for analysis down the line.

- Clustering
There are so many clustering methods out there that a simple list could make your head spin.

Agglomerative Clustering hierarchically divides a dataset into clusters
Agglomerative Clustering showing a hierarchy depending on the size of inherent classes within a data set
K-Means Clustering, Affinity Propagation, the DBSCAN Method, Hierarchical Clustering, Spectral Clustering, etc.; all serve one purpose, to group your data into rough stacks or piles.


DBSCAN Method showing sub optimal clustering for a data set (too many clusters)
With a basic clustering algorithm, you can find out how many classes or groups your data is divided into.

This is useful for a number of reasons. Say you’re trying to find an ideal demographic to price a product. Clustering methods will identify broad groups for you to break down in your analysis, all without any classification method.

This is a very useful method that will help you build a roadmap towards your goal.

- Heatmaps
If you’re looking to find important links between different features in your data set, look no further than heatmaps.

Heatmaps can show you close relationship (positive or negative) between data set features


![image](https://user-images.githubusercontent.com/100648556/171470284-f4631226-8588-4871-ae01-85d3cc975d94.png)


